from typing import Any, Callable, Literal, Optional, Tuple, Type, TypeVar, Sequence

from gi.repository import GLib
from gi.repository import GObject
from gi.repository import Gst
from gi.repository import GstBase


AUDIO_CHANNELS_RANGE: str = "(int) [ 1, max ]"
AUDIO_CONVERTER_OPT_DITHER_METHOD: str = "GstAudioConverter.dither-method"
AUDIO_CONVERTER_OPT_DITHER_THRESHOLD: str = "GstAudioConverter.dither-threshold"
AUDIO_CONVERTER_OPT_MIX_MATRIX: str = "GstAudioConverter.mix-matrix"
AUDIO_CONVERTER_OPT_NOISE_SHAPING_METHOD: str = "GstAudioConverter.noise-shaping-method"
AUDIO_CONVERTER_OPT_QUANTIZATION: str = "GstAudioConverter.quantization"
AUDIO_CONVERTER_OPT_RESAMPLER_METHOD: str = "GstAudioConverter.resampler-method"
AUDIO_DECODER_MAX_ERRORS: int = -1
AUDIO_DECODER_SINK_NAME: str = "sink"
AUDIO_DECODER_SRC_NAME: str = "src"
AUDIO_DEF_CHANNELS: int = 2
AUDIO_DEF_FORMAT: str = "S16LE"
AUDIO_DEF_RATE: int = 44100
AUDIO_ENCODER_SINK_NAME: str = "sink"
AUDIO_ENCODER_SRC_NAME: str = "src"
AUDIO_FORMATS_ALL: str = "{ F64BE, F64LE, F32BE, F32LE, S32BE, S32LE, U32BE, U32LE, S24_32BE, S24_32LE, U24_32BE, U24_32LE, S24BE, S24LE, U24BE, U24LE, S20BE, S20LE, U20BE, U20LE, S18BE, S18LE, U18BE, U18LE, S16BE, S16LE, U16BE, U16LE, S8, U8 }"
AUDIO_RATE_RANGE: str = "(int) [ 1, max ]"
AUDIO_RESAMPLER_OPT_CUBIC_B: str = "GstAudioResampler.cubic-b"
AUDIO_RESAMPLER_OPT_CUBIC_C: str = "GstAudioResampler.cubic-c"
AUDIO_RESAMPLER_OPT_CUTOFF: str = "GstAudioResampler.cutoff"
AUDIO_RESAMPLER_OPT_FILTER_INTERPOLATION: str = "GstAudioResampler.filter-interpolation"
AUDIO_RESAMPLER_OPT_FILTER_MODE: str = "GstAudioResampler.filter-mode"
AUDIO_RESAMPLER_OPT_FILTER_MODE_THRESHOLD: str = "GstAudioResampler.filter-mode-threshold"
AUDIO_RESAMPLER_OPT_FILTER_OVERSAMPLE: str = "GstAudioResampler.filter-oversample"
AUDIO_RESAMPLER_OPT_MAX_PHASE_ERROR: str = "GstAudioResampler.max-phase-error"
AUDIO_RESAMPLER_OPT_N_TAPS: str = "GstAudioResampler.n-taps"
AUDIO_RESAMPLER_OPT_STOP_ATTENUATION: str = "GstAudioResampler.stop-attenutation"
AUDIO_RESAMPLER_OPT_TRANSITION_BANDWIDTH: str = "GstAudioResampler.transition-bandwidth"
AUDIO_RESAMPLER_QUALITY_DEFAULT: int = 4
AUDIO_RESAMPLER_QUALITY_MAX: int = 10
AUDIO_RESAMPLER_QUALITY_MIN: int = 0
META_TAG_AUDIO_CHANNELS_STR: str = "channels"
META_TAG_AUDIO_RATE_STR: str = "rate"
META_TAG_AUDIO_STR: str = "audio"
_introspection_module = ... # FIXME Constant
_lock = ... # FIXME Constant
_namespace: str = "GstAudio"
_overrides_module = ... # FIXME Constant
_version: str = "1.0"

def audio_buffer_clip(buffer: Gst.Buffer, segment: Gst.Segment, rate: int, bpf: int) -> Optional[Gst.Buffer]: ...
def audio_buffer_map(info: AudioInfo, gstbuffer: Gst.Buffer, flags: Gst.MapFlags) -> Tuple[bool, AudioBuffer]: ...
def audio_buffer_reorder_channels(buffer: Gst.Buffer, format: AudioFormat, from_: Sequence[AudioChannelPosition], to: Sequence[AudioChannelPosition]) -> bool: ...
def audio_buffer_truncate(buffer: Gst.Buffer, bpf: int, trim: int, samples: int) -> Gst.Buffer: ...
def audio_channel_get_fallback_mask(channels: int) -> int: ...
def audio_channel_positions_from_mask(channel_mask: int, position: Sequence[AudioChannelPosition]) -> bool: ...
def audio_channel_positions_to_mask(position: Sequence[AudioChannelPosition], force_order: bool) -> Tuple[bool, int]: ...
def audio_channel_positions_to_string(position: Sequence[AudioChannelPosition]) -> str: ...
def audio_channel_positions_to_valid_order(position: Sequence[AudioChannelPosition]) -> bool: ...
def audio_check_valid_channel_positions(position: Sequence[AudioChannelPosition], force_order: bool) -> bool: ...
def audio_clipping_meta_api_get_type() -> Type: ...
def audio_clipping_meta_get_info() -> Gst.MetaInfo: ...
def audio_downmix_meta_api_get_type() -> Type: ...
def audio_downmix_meta_get_info() -> Gst.MetaInfo: ...
def audio_format_build_integer(sign: bool, endianness: int, width: int, depth: int) -> AudioFormat: ...
def audio_format_fill_silence(info: AudioFormatInfo, dest: Sequence[int]) -> None: ...
def audio_format_from_string(format: str) -> AudioFormat: ...
def audio_format_get_info(format: AudioFormat) -> AudioFormatInfo: ...
def audio_format_info_get_type() -> Type: ...
def audio_format_to_string(format: AudioFormat) -> str: ...
def audio_formats_raw() -> list[AudioFormat]: ...
def audio_get_channel_reorder_map(from_: Sequence[AudioChannelPosition], to: Sequence[AudioChannelPosition], reorder_map: Sequence[int]) -> bool: ...
def audio_iec61937_frame_size(spec: AudioRingBufferSpec) -> int: ...
def audio_iec61937_payload(src: Sequence[int], dst: Sequence[int], spec: AudioRingBufferSpec, endianness: int) -> bool: ...
def audio_info_from_caps(caps: Gst.Caps) -> Tuple[bool, AudioInfo]: ...
def audio_info_init() -> AudioInfo: ...
def audio_level_meta_api_get_type() -> Type: ...
def audio_level_meta_get_info() -> Gst.MetaInfo: ...
def audio_make_raw_caps(formats: Optional[Sequence[AudioFormat]], layout: AudioLayout) -> Gst.Caps: ...
def audio_meta_api_get_type() -> Type: ...
def audio_meta_get_info() -> Gst.MetaInfo: ...
def audio_reorder_channels(data: Sequence[int], format: AudioFormat, from_: Sequence[AudioChannelPosition], to: Sequence[AudioChannelPosition]) -> bool: ...
def audio_resampler_new(method: AudioResamplerMethod, flags: AudioResamplerFlags, format: AudioFormat, channels: int, in_rate: int, out_rate: int, options: Gst.Structure) -> AudioResampler: ...
def audio_resampler_options_set_quality(method: AudioResamplerMethod, quality: int, in_rate: int, out_rate: int, options: Gst.Structure) -> None: ...
def buffer_add_audio_clipping_meta(buffer: Gst.Buffer, format: Gst.Format, start: int, end: int) -> AudioClippingMeta: ...
def buffer_add_audio_downmix_meta(buffer: Gst.Buffer, from_position: Sequence[AudioChannelPosition], to_position: Sequence[AudioChannelPosition], matrix: float) -> AudioDownmixMeta: ...
def buffer_add_audio_level_meta(buffer: Gst.Buffer, level: int, voice_activity: bool) -> Optional[AudioLevelMeta]: ...
def buffer_add_audio_meta(buffer: Gst.Buffer, info: AudioInfo, samples: int, offsets: Optional[int] = None) -> AudioMeta: ...
def buffer_get_audio_downmix_meta_for_channels(buffer: Gst.Buffer, to_position: Sequence[AudioChannelPosition]) -> AudioDownmixMeta: ...
def buffer_get_audio_level_meta(buffer: Gst.Buffer) -> Optional[AudioLevelMeta]: ...
def stream_volume_convert_volume(from_: StreamVolumeFormat, to: StreamVolumeFormat, val: float) -> float: ...

class AudioAggregator(GstBase.Aggregator):
    class Props:
        alignment_threshold: int
        discont_wait: int
        force_live: bool
        ignore_inactive_pads: bool
        output_buffer_duration: int
        output_buffer_duration_fraction: Gst.Fraction
        emit_signals: bool
        latency: int
        min_upstream_latency: int
        start_time: int
        start_time_selection: GstBase.AggregatorStartTimeSelection
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    parent: GstBase.Aggregator = ...
    current_caps: Gst.Caps = ...
    priv: AudioAggregatorPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, alignment_threshold: int = ...,
                 discont_wait: int = ...,
                 force_live: bool = ...,
                 ignore_inactive_pads: bool = ...,
                 output_buffer_duration: int = ...,
                 output_buffer_duration_fraction: Gst.Fraction = ...,
                 emit_signals: bool = ...,
                 latency: int = ...,
                 min_upstream_latency: int = ...,
                 start_time: int = ...,
                 start_time_selection: GstBase.AggregatorStartTimeSelection = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def do_aggregate_one_buffer(self, pad: AudioAggregatorPad, inbuf: Gst.Buffer, in_offset: int, outbuf: Gst.Buffer, out_offset: int, num_frames: int) -> bool: ...
    def do_create_output_buffer(self, num_frames: int) -> Gst.Buffer: ...
    def set_sink_caps(self, pad: AudioAggregatorPad, caps: Gst.Caps) -> None: ...
    

class AudioAggregatorClass(GObject.GPointer):
    parent_class: GstBase.AggregatorClass = ...
    create_output_buffer: Callable[[AudioAggregator, int], Gst.Buffer] = ...
    aggregate_one_buffer: Callable[[AudioAggregator, AudioAggregatorPad, Gst.Buffer, int, Gst.Buffer, int, int], bool] = ...
    _gst_reserved: list[None] = ...

class AudioAggregatorConvertPad(AudioAggregatorPad):
    class Props:
        converter_config: Gst.Structure
        qos_messages: bool
        emit_signals: bool
        caps: Gst.Caps
        direction: Gst.PadDirection
        offset: int
        template: Gst.PadTemplate
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    parent: AudioAggregatorPad = ...
    priv: AudioAggregatorConvertPadPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, converter_config: Gst.Structure = ...,
                 qos_messages: bool = ...,
                 emit_signals: bool = ...,
                 direction: Gst.PadDirection = ...,
                 offset: int = ...,
                 template: Gst.PadTemplate = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...

class AudioAggregatorConvertPadClass(GObject.GPointer):
    parent_class: AudioAggregatorPadClass = ...
    _gst_reserved: list[None] = ...

class AudioAggregatorConvertPadPrivate(GObject.GPointer): ...

class AudioAggregatorPad(GstBase.AggregatorPad):
    class Props:
        qos_messages: bool
        emit_signals: bool
        caps: Gst.Caps
        direction: Gst.PadDirection
        offset: int
        template: Gst.PadTemplate
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    parent: GstBase.AggregatorPad = ...
    info: AudioInfo = ...
    priv: AudioAggregatorPadPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, qos_messages: bool = ...,
                 emit_signals: bool = ...,
                 direction: Gst.PadDirection = ...,
                 offset: int = ...,
                 template: Gst.PadTemplate = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def do_convert_buffer(self, in_info: AudioInfo, out_info: AudioInfo, buffer: Gst.Buffer) -> Gst.Buffer: ...
    def do_update_conversion_info(self) -> None: ...
    

class AudioAggregatorPadClass(GObject.GPointer):
    parent_class: GstBase.AggregatorPadClass = ...
    convert_buffer: Callable[[AudioAggregatorPad, AudioInfo, AudioInfo, Gst.Buffer], Gst.Buffer] = ...
    update_conversion_info: Callable[[AudioAggregatorPad], None] = ...
    _gst_reserved: list[None] = ...

class AudioAggregatorPadPrivate(GObject.GPointer): ...

class AudioAggregatorPrivate(GObject.GPointer): ...

class AudioBaseSink(GstBase.BaseSink):
    class Props:
        alignment_threshold: int
        buffer_time: int
        can_activate_pull: bool
        discont_wait: int
        drift_tolerance: int
        latency_time: int
        provide_clock: bool
        slave_method: AudioBaseSinkSlaveMethod
        async: bool
        blocksize: int
        enable_last_sample: bool
        last_sample: Optional[Gst.Sample]
        max_bitrate: int
        max_lateness: int
        processing_deadline: int
        qos: bool
        render_delay: int
        stats: Gst.Structure
        sync: bool
        throttle_time: int
        ts_offset: int
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    element: GstBase.BaseSink = ...
    ringbuffer: AudioRingBuffer = ...
    buffer_time: int = ...
    latency_time: int = ...
    next_sample: int = ...
    provided_clock: Gst.Clock = ...
    eos_rendering: bool = ...
    priv: AudioBaseSinkPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, alignment_threshold: int = ...,
                 buffer_time: int = ...,
                 can_activate_pull: bool = ...,
                 discont_wait: int = ...,
                 drift_tolerance: int = ...,
                 latency_time: int = ...,
                 provide_clock: bool = ...,
                 slave_method: AudioBaseSinkSlaveMethod = ...,
                 async: bool = ...,
                 blocksize: int = ...,
                 enable_last_sample: bool = ...,
                 max_bitrate: int = ...,
                 max_lateness: int = ...,
                 processing_deadline: int = ...,
                 qos: bool = ...,
                 render_delay: int = ...,
                 sync: bool = ...,
                 throttle_time: int = ...,
                 ts_offset: int = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def create_ringbuffer(self) -> Optional[AudioRingBuffer]: ...
    def do_create_ringbuffer(self) -> Optional[AudioRingBuffer]: ...
    def do_payload(self, buffer: Gst.Buffer) -> Gst.Buffer: ...
    def get_alignment_threshold(self) -> int: ...
    def get_discont_wait(self) -> int: ...
    def get_drift_tolerance(self) -> int: ...
    def get_provide_clock(self) -> bool: ...
    def get_slave_method(self) -> AudioBaseSinkSlaveMethod: ...
    def report_device_failure(self) -> None: ...
    def set_alignment_threshold(self, alignment_threshold: int) -> None: ...
    def set_custom_slaving_callback(self, callback: Callable[..., None], *user_data: Any) -> None: ...
    def set_discont_wait(self, discont_wait: int) -> None: ...
    def set_drift_tolerance(self, drift_tolerance: int) -> None: ...
    def set_provide_clock(self, provide: bool) -> None: ...
    def set_slave_method(self, method: AudioBaseSinkSlaveMethod) -> None: ...
    

class AudioBaseSinkClass(GObject.GPointer):
    parent_class: GstBase.BaseSinkClass = ...
    create_ringbuffer: Callable[[AudioBaseSink], Optional[AudioRingBuffer]] = ...
    payload: Callable[[AudioBaseSink, Gst.Buffer], Gst.Buffer] = ...
    _gst_reserved: list[None] = ...

class AudioBaseSinkPrivate(GObject.GPointer): ...

class AudioBaseSrc(GstBase.PushSrc):
    class Props:
        actual_buffer_time: int
        actual_latency_time: int
        buffer_time: int
        latency_time: int
        provide_clock: bool
        slave_method: AudioBaseSrcSlaveMethod
        blocksize: int
        do_timestamp: bool
        num_buffers: int
        typefind: bool
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    element: GstBase.PushSrc = ...
    ringbuffer: AudioRingBuffer = ...
    buffer_time: int = ...
    latency_time: int = ...
    next_sample: int = ...
    clock: Gst.Clock = ...
    priv: AudioBaseSrcPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, buffer_time: int = ...,
                 latency_time: int = ...,
                 provide_clock: bool = ...,
                 slave_method: AudioBaseSrcSlaveMethod = ...,
                 blocksize: int = ...,
                 do_timestamp: bool = ...,
                 num_buffers: int = ...,
                 typefind: bool = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def create_ringbuffer(self) -> Optional[AudioRingBuffer]: ...
    def do_create_ringbuffer(self) -> Optional[AudioRingBuffer]: ...
    def get_provide_clock(self) -> bool: ...
    def get_slave_method(self) -> AudioBaseSrcSlaveMethod: ...
    def set_provide_clock(self, provide: bool) -> None: ...
    def set_slave_method(self, method: AudioBaseSrcSlaveMethod) -> None: ...
    

class AudioBaseSrcClass(GObject.GPointer):
    parent_class: GstBase.PushSrcClass = ...
    create_ringbuffer: Callable[[AudioBaseSrc], Optional[AudioRingBuffer]] = ...
    _gst_reserved: list[None] = ...

class AudioBaseSrcPrivate(GObject.GPointer): ...

class AudioBuffer(GObject.GPointer):
    info: AudioInfo = ...
    n_samples: int = ...
    n_planes: int = ...
    planes: None = ...
    buffer: Gst.Buffer = ...
    map_infos: Gst.MapInfo = ...
    priv_planes_arr: list[None] = ...
    priv_map_infos_arr: list[Gst.MapInfo] = ...
    _gst_reserved: list[None] = ...
    @staticmethod
    def clip(buffer: Gst.Buffer, segment: Gst.Segment, rate: int, bpf: int) -> Optional[Gst.Buffer]: ...
    @staticmethod
    def map(info: AudioInfo, gstbuffer: Gst.Buffer, flags: Gst.MapFlags) -> Tuple[bool, AudioBuffer]: ...
    @staticmethod
    def reorder_channels(buffer: Gst.Buffer, format: AudioFormat, from_: Sequence[AudioChannelPosition], to: Sequence[AudioChannelPosition]) -> bool: ...
    @staticmethod
    def truncate(buffer: Gst.Buffer, bpf: int, trim: int, samples: int) -> Gst.Buffer: ...
    def unmap(self) -> None: ...
    

class AudioCdSrc(GstBase.PushSrc, Gst.URIHandler):
    class Props:
        device: str
        mode: AudioCdSrcMode
        track: int
        blocksize: int
        do_timestamp: bool
        num_buffers: int
        typefind: bool
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    pushsrc: GstBase.PushSrc = ...
    tags: Gst.TagList = ...
    priv: AudioCdSrcPrivate = ...
    _gst_reserved1: list[int] = ...
    _gst_reserved2: list[None] = ...
    def __init__(self, device: str = ...,
                 mode: AudioCdSrcMode = ...,
                 track: int = ...,
                 blocksize: int = ...,
                 do_timestamp: bool = ...,
                 num_buffers: int = ...,
                 typefind: bool = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def add_track(self, track: AudioCdSrcTrack) -> bool: ...
    def do_close(self) -> None: ...
    def do_open(self, device: str) -> bool: ...
    def do_read_sector(self, sector: int) -> Gst.Buffer: ...
    

class AudioCdSrcClass(GObject.GPointer):
    pushsrc_class: GstBase.PushSrcClass = ...
    open: Callable[[AudioCdSrc, str], bool] = ...
    close: Callable[[AudioCdSrc], None] = ...
    read_sector: Callable[[AudioCdSrc, int], Gst.Buffer] = ...
    _gst_reserved: list[None] = ...

class AudioCdSrcPrivate(GObject.GPointer): ...

class AudioCdSrcTrack(GObject.GPointer):
    is_audio: bool = ...
    num: int = ...
    start: int = ...
    end: int = ...
    tags: Gst.TagList = ...
    _gst_reserved1: list[int] = ...
    _gst_reserved2: list[None] = ...

class AudioChannelMixer(GObject.GPointer):
    def free(self) -> None: ...
    def is_passthrough(self) -> bool: ...
    def samples(self, in_: None, out: None, samples: int) -> None: ...
    

class AudioClippingMeta(GObject.GPointer):
    meta: Gst.Meta = ...
    format: Gst.Format = ...
    start: int = ...
    end: int = ...
    @staticmethod
    def get_info() -> Gst.MetaInfo: ...
    

class AudioClock(Gst.SystemClock):
    class Props:
        clock_type: Gst.ClockType
        timeout: int
        window_size: int
        window_threshold: int
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    clock: Gst.SystemClock = ...
    func: Callable[..., int] = ...
    user_data: None = ...
    destroy_notify: Callable[[None], None] = ...
    last_time: int = ...
    time_offset: int = ...
    _gst_reserved: list[None] = ...
    def __init__(self, clock_type: Gst.ClockType = ...,
                 timeout: int = ...,
                 window_size: int = ...,
                 window_threshold: int = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def adjust(self, time: int) -> int: ...
    def get_time(self) -> int: ...
    def invalidate(self) -> None: ...
    @classmethod
    def new(cls, name: str, func: Callable[..., int], *user_data: Any) -> AudioClock: ...
    def reset(self, time: int) -> None: ...
    

class AudioClockClass(GObject.GPointer):
    parent_class: Gst.SystemClockClass = ...
    _gst_reserved: list[None] = ...

class AudioConverter(GObject.GBoxed):
    def convert(self, flags: AudioConverterFlags, in_: Sequence[int]) -> Tuple[bool, bytes]: ...
    def free(self) -> None: ...
    def get_config(self) -> Tuple[Gst.Structure, int, int]: ...
    def get_in_frames(self, out_frames: int) -> int: ...
    def get_max_latency(self) -> int: ...
    def get_out_frames(self, in_frames: int) -> int: ...
    def is_passthrough(self) -> bool: ...
    @classmethod
    def new(cls, flags: AudioConverterFlags, in_info: AudioInfo, out_info: AudioInfo, config: Optional[Gst.Structure] = None) -> Optional[AudioConverter]: ...
    def reset(self) -> None: ...
    def samples(self, flags: AudioConverterFlags, in_: None, in_frames: int, out: None, out_frames: int) -> bool: ...
    def supports_inplace(self) -> bool: ...
    def update_config(self, in_rate: int, out_rate: int, config: Optional[Gst.Structure] = None) -> bool: ...
    

class AudioDecoder(Gst.Element):
    class Props:
        max_errors: int
        min_latency: int
        plc: bool
        tolerance: int
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    element: Gst.Element = ...
    sinkpad: Gst.Pad = ...
    srcpad: Gst.Pad = ...
    stream_lock: GLib.RecMutex = ...
    input_segment: Gst.Segment = ...
    output_segment: Gst.Segment = ...
    priv: AudioDecoderPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, max_errors: int = ...,
                 min_latency: int = ...,
                 plc: bool = ...,
                 tolerance: int = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def allocate_output_buffer(self, size: int) -> Gst.Buffer: ...
    def do_close(self) -> bool: ...
    def do_decide_allocation(self, query: Gst.Query) -> bool: ...
    def do_flush(self, hard: bool) -> None: ...
    def do_getcaps(self, filter: Gst.Caps) -> Gst.Caps: ...
    def do_handle_frame(self, buffer: Gst.Buffer) -> Gst.FlowReturn: ...
    def do_negotiate(self) -> bool: ...
    def do_open(self) -> bool: ...
    def do_parse(self, adapter: GstBase.Adapter) -> Tuple[Gst.FlowReturn, int, int]: ...
    def do_pre_push(self, buffer: Gst.Buffer) -> Gst.FlowReturn: ...
    def do_propose_allocation(self, query: Gst.Query) -> bool: ...
    def do_set_format(self, caps: Gst.Caps) -> bool: ...
    def do_sink_event(self, event: Gst.Event) -> bool: ...
    def do_sink_query(self, query: Gst.Query) -> bool: ...
    def do_src_event(self, event: Gst.Event) -> bool: ...
    def do_src_query(self, query: Gst.Query) -> bool: ...
    def do_start(self) -> bool: ...
    def do_stop(self) -> bool: ...
    def do_transform_meta(self, outbuf: Gst.Buffer, meta: Gst.Meta, inbuf: Gst.Buffer) -> bool: ...
    def finish_frame(self, buf: Optional[Gst.Buffer], frames: int) -> Gst.FlowReturn: ...
    def finish_subframe(self, buf: Optional[Gst.Buffer] = None) -> Gst.FlowReturn: ...
    def get_allocator(self) -> Tuple[Gst.Allocator, Gst.AllocationParams]: ...
    def get_audio_info(self) -> AudioInfo: ...
    def get_delay(self) -> int: ...
    def get_drainable(self) -> bool: ...
    def get_estimate_rate(self) -> int: ...
    def get_latency(self) -> Tuple[int, int]: ...
    def get_max_errors(self) -> int: ...
    def get_min_latency(self) -> int: ...
    def get_needs_format(self) -> bool: ...
    def get_parse_state(self) -> Tuple[bool, bool]: ...
    def get_plc(self) -> bool: ...
    def get_plc_aware(self) -> int: ...
    def get_tolerance(self) -> int: ...
    def merge_tags(self, tags: Optional[Gst.TagList], mode: Gst.TagMergeMode) -> None: ...
    def negotiate(self) -> bool: ...
    def proxy_getcaps(self, caps: Optional[Gst.Caps] = None, filter: Optional[Gst.Caps] = None) -> Gst.Caps: ...
    def set_allocation_caps(self, allocation_caps: Optional[Gst.Caps] = None) -> None: ...
    def set_drainable(self, enabled: bool) -> None: ...
    def set_estimate_rate(self, enabled: bool) -> None: ...
    def set_latency(self, min: int, max: int) -> None: ...
    def set_max_errors(self, num: int) -> None: ...
    def set_min_latency(self, num: int) -> None: ...
    def set_needs_format(self, enabled: bool) -> None: ...
    def set_output_caps(self, caps: Gst.Caps) -> bool: ...
    def set_output_format(self, info: AudioInfo) -> bool: ...
    def set_plc(self, enabled: bool) -> None: ...
    def set_plc_aware(self, plc: bool) -> None: ...
    def set_tolerance(self, tolerance: int) -> None: ...
    def set_use_default_pad_acceptcaps(self, use: bool) -> None: ...
    

class AudioDecoderClass(GObject.GPointer):
    element_class: Gst.ElementClass = ...
    start: Callable[[AudioDecoder], bool] = ...
    stop: Callable[[AudioDecoder], bool] = ...
    set_format: Callable[[AudioDecoder, Gst.Caps], bool] = ...
    parse: Callable[[AudioDecoder, GstBase.Adapter], Tuple[Gst.FlowReturn, int, int]] = ...
    handle_frame: Callable[[AudioDecoder, Gst.Buffer], Gst.FlowReturn] = ...
    flush: Callable[[AudioDecoder, bool], None] = ...
    pre_push: Callable[[AudioDecoder, Gst.Buffer], Gst.FlowReturn] = ...
    sink_event: Callable[[AudioDecoder, Gst.Event], bool] = ...
    src_event: Callable[[AudioDecoder, Gst.Event], bool] = ...
    open: Callable[[AudioDecoder], bool] = ...
    close: Callable[[AudioDecoder], bool] = ...
    negotiate: Callable[[AudioDecoder], bool] = ...
    decide_allocation: Callable[[AudioDecoder, Gst.Query], bool] = ...
    propose_allocation: Callable[[AudioDecoder, Gst.Query], bool] = ...
    sink_query: Callable[[AudioDecoder, Gst.Query], bool] = ...
    src_query: Callable[[AudioDecoder, Gst.Query], bool] = ...
    getcaps: Callable[[AudioDecoder, Gst.Caps], Gst.Caps] = ...
    transform_meta: Callable[[AudioDecoder, Gst.Buffer, Gst.Meta, Gst.Buffer], bool] = ...
    _gst_reserved: list[None] = ...

class AudioDecoderPrivate(GObject.GPointer): ...

class AudioDownmixMeta(GObject.GPointer):
    meta: Gst.Meta = ...
    from_position: AudioChannelPosition = ...
    to_position: AudioChannelPosition = ...
    from_channels: int = ...
    to_channels: int = ...
    matrix: float = ...
    @staticmethod
    def get_info() -> Gst.MetaInfo: ...
    

class AudioEncoder(Gst.Element, Gst.Preset):
    class Props:
        hard_resync: bool
        mark_granule: bool
        perfect_timestamp: bool
        tolerance: int
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    element: Gst.Element = ...
    sinkpad: Gst.Pad = ...
    srcpad: Gst.Pad = ...
    stream_lock: GLib.RecMutex = ...
    input_segment: Gst.Segment = ...
    output_segment: Gst.Segment = ...
    priv: AudioEncoderPrivate = ...
    _gst_reserved: list[None] = ...
    def __init__(self, hard_resync: bool = ...,
                 perfect_timestamp: bool = ...,
                 tolerance: int = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def allocate_output_buffer(self, size: int) -> Gst.Buffer: ...
    def do_close(self) -> bool: ...
    def do_decide_allocation(self, query: Gst.Query) -> bool: ...
    def do_flush(self) -> None: ...
    def do_getcaps(self, filter: Gst.Caps) -> Gst.Caps: ...
    def do_handle_frame(self, buffer: Gst.Buffer) -> Gst.FlowReturn: ...
    def do_negotiate(self) -> bool: ...
    def do_open(self) -> bool: ...
    def do_pre_push(self, buffer: Gst.Buffer) -> Gst.FlowReturn: ...
    def do_propose_allocation(self, query: Gst.Query) -> bool: ...
    def do_set_format(self, info: AudioInfo) -> bool: ...
    def do_sink_event(self, event: Gst.Event) -> bool: ...
    def do_sink_query(self, query: Gst.Query) -> bool: ...
    def do_src_event(self, event: Gst.Event) -> bool: ...
    def do_src_query(self, query: Gst.Query) -> bool: ...
    def do_start(self) -> bool: ...
    def do_stop(self) -> bool: ...
    def do_transform_meta(self, outbuf: Gst.Buffer, meta: Gst.Meta, inbuf: Gst.Buffer) -> bool: ...
    def finish_frame(self, buffer: Optional[Gst.Buffer], samples: int) -> Gst.FlowReturn: ...
    def get_allocator(self) -> Tuple[Gst.Allocator, Gst.AllocationParams]: ...
    def get_audio_info(self) -> AudioInfo: ...
    def get_drainable(self) -> bool: ...
    def get_frame_max(self) -> int: ...
    def get_frame_samples_max(self) -> int: ...
    def get_frame_samples_min(self) -> int: ...
    def get_hard_min(self) -> bool: ...
    def get_hard_resync(self) -> bool: ...
    def get_latency(self) -> Tuple[int, int]: ...
    def get_lookahead(self) -> int: ...
    def get_mark_granule(self) -> bool: ...
    def get_perfect_timestamp(self) -> bool: ...
    def get_tolerance(self) -> int: ...
    def merge_tags(self, tags: Optional[Gst.TagList], mode: Gst.TagMergeMode) -> None: ...
    def negotiate(self) -> bool: ...
    def proxy_getcaps(self, caps: Optional[Gst.Caps] = None, filter: Optional[Gst.Caps] = None) -> Gst.Caps: ...
    def set_allocation_caps(self, allocation_caps: Optional[Gst.Caps] = None) -> None: ...
    def set_drainable(self, enabled: bool) -> None: ...
    def set_frame_max(self, num: int) -> None: ...
    def set_frame_samples_max(self, num: int) -> None: ...
    def set_frame_samples_min(self, num: int) -> None: ...
    def set_hard_min(self, enabled: bool) -> None: ...
    def set_hard_resync(self, enabled: bool) -> None: ...
    def set_headers(self, headers: list[Gst.Buffer]) -> None: ...
    def set_latency(self, min: int, max: int) -> None: ...
    def set_lookahead(self, num: int) -> None: ...
    def set_mark_granule(self, enabled: bool) -> None: ...
    def set_output_format(self, caps: Gst.Caps) -> bool: ...
    def set_perfect_timestamp(self, enabled: bool) -> None: ...
    def set_tolerance(self, tolerance: int) -> None: ...
    

class AudioEncoderClass(GObject.GPointer):
    element_class: Gst.ElementClass = ...
    start: Callable[[AudioEncoder], bool] = ...
    stop: Callable[[AudioEncoder], bool] = ...
    set_format: Callable[[AudioEncoder, AudioInfo], bool] = ...
    handle_frame: Callable[[AudioEncoder, Gst.Buffer], Gst.FlowReturn] = ...
    flush: Callable[[AudioEncoder], None] = ...
    pre_push: Callable[[AudioEncoder, Gst.Buffer], Gst.FlowReturn] = ...
    sink_event: Callable[[AudioEncoder, Gst.Event], bool] = ...
    src_event: Callable[[AudioEncoder, Gst.Event], bool] = ...
    getcaps: Callable[[AudioEncoder, Gst.Caps], Gst.Caps] = ...
    open: Callable[[AudioEncoder], bool] = ...
    close: Callable[[AudioEncoder], bool] = ...
    negotiate: Callable[[AudioEncoder], bool] = ...
    decide_allocation: Callable[[AudioEncoder, Gst.Query], bool] = ...
    propose_allocation: Callable[[AudioEncoder, Gst.Query], bool] = ...
    transform_meta: Callable[[AudioEncoder, Gst.Buffer, Gst.Meta, Gst.Buffer], bool] = ...
    sink_query: Callable[[AudioEncoder, Gst.Query], bool] = ...
    src_query: Callable[[AudioEncoder, Gst.Query], bool] = ...
    _gst_reserved: list[None] = ...

class AudioEncoderPrivate(GObject.GPointer): ...

class AudioFilter(GstBase.BaseTransform):
    class Props:
        qos: bool
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    basetransform: GstBase.BaseTransform = ...
    info: AudioInfo = ...
    _gst_reserved: list[None] = ...
    def __init__(self, qos: bool = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def add_pad_templates(self, allowed_caps: Gst.Caps) -> None: ...
    def do_setup(self, info: AudioInfo) -> bool: ...
    

class AudioFilterClass(GObject.GPointer):
    basetransformclass: GstBase.BaseTransformClass = ...
    setup: Callable[[AudioFilter, AudioInfo], bool] = ...
    _gst_reserved: list[None] = ...
    def add_pad_templates(self, allowed_caps: Gst.Caps) -> None: ...
    

class AudioFormatInfo(GObject.GPointer):
    format: AudioFormat = ...
    name: str = ...
    description: str = ...
    flags: AudioFormatFlags = ...
    endianness: int = ...
    width: int = ...
    depth: int = ...
    silence: bytes = ...
    unpack_format: AudioFormat = ...
    unpack_func: Callable[[AudioFormatInfo, AudioPackFlags, Sequence[int], Sequence[int], int], None] = ...
    pack_func: Callable[[AudioFormatInfo, AudioPackFlags, Sequence[int], Sequence[int], int], None] = ...
    _gst_reserved: list[None] = ...
    def fill_silence(self, dest: Sequence[int]) -> None: ...
    

class AudioInfo(GObject.GBoxed):
    finfo: AudioFormatInfo = ...
    flags: AudioFlags = ...
    layout: AudioLayout = ...
    rate: int = ...
    channels: int = ...
    bpf: int = ...
    position: list[AudioChannelPosition] = ...
    _gst_reserved: list[None] = ...
    def convert(self, src_fmt: Gst.Format, src_val: int, dest_fmt: Gst.Format) -> Tuple[bool, int]: ...
    def copy(self) -> AudioInfo: ...
    def free(self) -> None: ...
    def from_caps(*args): ... # FIXME Function
    @staticmethod
    def init() -> AudioInfo: ...
    def is_equal(self, other: AudioInfo) -> bool: ...
    @classmethod
    def new(cls) -> AudioInfo: ...
    @classmethod
    def new_from_caps(cls, caps: Gst.Caps) -> Optional[AudioInfo]: ...
    def set_format(self, format: AudioFormat, rate: int, channels: int, position: Optional[Sequence[AudioChannelPosition]] = None) -> None: ...
    def to_caps(self) -> Gst.Caps: ...
    

class AudioLevelMeta(GObject.GPointer):
    meta: Gst.Meta = ...
    level: int = ...
    voice_activity: bool = ...
    @staticmethod
    def get_info() -> Gst.MetaInfo: ...
    

class AudioMeta(GObject.GPointer):
    meta: Gst.Meta = ...
    info: AudioInfo = ...
    samples: int = ...
    offsets: int = ...
    priv_offsets_arr: list[int] = ...
    _gst_reserved: list[None] = ...
    @staticmethod
    def get_info() -> Gst.MetaInfo: ...
    

class AudioQuantize(GObject.GPointer):
    def free(self) -> None: ...
    def reset(self) -> None: ...
    def samples(self, in_: None, out: None, samples: int) -> None: ...
    

class AudioResampler(GObject.GPointer):
    def free(self) -> None: ...
    def get_in_frames(self, out_frames: int) -> int: ...
    def get_max_latency(self) -> int: ...
    def get_out_frames(self, in_frames: int) -> int: ...
    @staticmethod
    def new(method: AudioResamplerMethod, flags: AudioResamplerFlags, format: AudioFormat, channels: int, in_rate: int, out_rate: int, options: Gst.Structure) -> AudioResampler: ...
    @staticmethod
    def options_set_quality(method: AudioResamplerMethod, quality: int, in_rate: int, out_rate: int, options: Gst.Structure) -> None: ...
    def resample(self, in_: None, in_frames: int, out: None, out_frames: int) -> None: ...
    def reset(self) -> None: ...
    def update(self, in_rate: int, out_rate: int, options: Gst.Structure) -> bool: ...
    

class AudioRingBuffer(Gst.Object):
    class Props:
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    object: Gst.Object = ...
    cond: GLib.Cond = ...
    open: bool = ...
    acquired: bool = ...
    memory: int = ...
    size: int = ...
    timestamps: int = ...
    spec: AudioRingBufferSpec = ...
    samples_per_seg: int = ...
    empty_seg: int = ...
    state: int = ...
    segdone: int = ...
    segbase: int = ...
    waiting: int = ...
    callback: Callable[..., None] = ...
    cb_data: None = ...
    need_reorder: bool = ...
    channel_reorder_map: list[int] = ...
    flushing: bool = ...
    may_start: int = ...
    active: bool = ...
    cb_data_notify: Callable[[None], None] = ...
    _gst_reserved: list[None] = ...
    def __init__(self, name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def acquire(self, spec: AudioRingBufferSpec) -> bool: ...
    def activate(self, active: bool) -> bool: ...
    def advance(self, advance: int) -> None: ...
    def clear(self, segment: int) -> None: ...
    def clear_all(self) -> None: ...
    def close_device(self) -> bool: ...
    def commit(self, data: Sequence[int], out_samples: int) -> Tuple[int, int, int]: ...
    def convert(self, src_fmt: Gst.Format, src_val: int, dest_fmt: Gst.Format) -> Tuple[bool, int]: ...
    @staticmethod
    def debug_spec_buff(spec: AudioRingBufferSpec) -> None: ...
    @staticmethod
    def debug_spec_caps(spec: AudioRingBufferSpec) -> None: ...
    def delay(self) -> int: ...
    def device_is_open(self) -> bool: ...
    def do_acquire(self, spec: AudioRingBufferSpec) -> bool: ...
    def do_activate(self, active: bool) -> bool: ...
    def do_clear_all(self) -> None: ...
    def do_close_device(self) -> bool: ...
    def do_commit(self, data: Sequence[int], out_samples: int) -> Tuple[int, int, int]: ...
    def do_delay(self) -> int: ...
    def do_open_device(self) -> bool: ...
    def do_pause(self) -> bool: ...
    def do_release(self) -> bool: ...
    def do_resume(self) -> bool: ...
    def do_start(self) -> bool: ...
    def do_stop(self) -> bool: ...
    def is_acquired(self) -> bool: ...
    def is_active(self) -> bool: ...
    def is_flushing(self) -> bool: ...
    def open_device(self) -> bool: ...
    @staticmethod
    def parse_caps(spec: AudioRingBufferSpec, caps: Gst.Caps) -> bool: ...
    def pause(self) -> bool: ...
    def prepare_read(self) -> Tuple[bool, int, bytes]: ...
    def read(self, sample: int, data: Sequence[int]) -> Tuple[int, int]: ...
    def release(self) -> bool: ...
    def samples_done(self) -> int: ...
    def set_callback(self, cb: Optional[Callable[..., None]] = None, *user_data: Any) -> None: ...
    def set_channel_positions(self, position: Sequence[AudioChannelPosition]) -> None: ...
    def set_flushing(self, flushing: bool) -> None: ...
    def set_sample(self, sample: int) -> None: ...
    def set_timestamp(self, readseg: int, timestamp: int) -> None: ...
    def start(self) -> bool: ...
    def stop(self) -> bool: ...
    

class AudioRingBufferClass(GObject.GPointer):
    parent_class: Gst.ObjectClass = ...
    open_device: Callable[[AudioRingBuffer], bool] = ...
    acquire: Callable[[AudioRingBuffer, AudioRingBufferSpec], bool] = ...
    release: Callable[[AudioRingBuffer], bool] = ...
    close_device: Callable[[AudioRingBuffer], bool] = ...
    start: Callable[[AudioRingBuffer], bool] = ...
    pause: Callable[[AudioRingBuffer], bool] = ...
    resume: Callable[[AudioRingBuffer], bool] = ...
    stop: Callable[[AudioRingBuffer], bool] = ...
    delay: Callable[[AudioRingBuffer], int] = ...
    activate: Callable[[AudioRingBuffer, bool], bool] = ...
    commit: Callable[[AudioRingBuffer, Sequence[int], int], Tuple[int, int, int]] = ...
    clear_all: Callable[[AudioRingBuffer], None] = ...
    _gst_reserved: list[None] = ...

class AudioRingBufferSpec(GObject.GPointer):
    caps: Gst.Caps = ...
    type: AudioRingBufferFormatType = ...
    info: AudioInfo = ...
    latency_time: int = ...
    buffer_time: int = ...
    segsize: int = ...
    segtotal: int = ...
    seglatency: int = ...
    _gst_reserved: list[None] = ...

class AudioSink(AudioBaseSink):
    class Props:
        alignment_threshold: int
        buffer_time: int
        can_activate_pull: bool
        discont_wait: int
        drift_tolerance: int
        latency_time: int
        provide_clock: bool
        slave_method: AudioBaseSinkSlaveMethod
        async: bool
        blocksize: int
        enable_last_sample: bool
        last_sample: Optional[Gst.Sample]
        max_bitrate: int
        max_lateness: int
        processing_deadline: int
        qos: bool
        render_delay: int
        stats: Gst.Structure
        sync: bool
        throttle_time: int
        ts_offset: int
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    element: AudioBaseSink = ...
    thread: GLib.Thread = ...
    _gst_reserved: list[None] = ...
    def __init__(self, alignment_threshold: int = ...,
                 buffer_time: int = ...,
                 can_activate_pull: bool = ...,
                 discont_wait: int = ...,
                 drift_tolerance: int = ...,
                 latency_time: int = ...,
                 provide_clock: bool = ...,
                 slave_method: AudioBaseSinkSlaveMethod = ...,
                 async: bool = ...,
                 blocksize: int = ...,
                 enable_last_sample: bool = ...,
                 max_bitrate: int = ...,
                 max_lateness: int = ...,
                 processing_deadline: int = ...,
                 qos: bool = ...,
                 render_delay: int = ...,
                 sync: bool = ...,
                 throttle_time: int = ...,
                 ts_offset: int = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def do_close(self) -> bool: ...
    def do_delay(self) -> int: ...
    def do_open(self) -> bool: ...
    def do_pause(self) -> None: ...
    def do_reset(self) -> None: ...
    def do_resume(self) -> None: ...
    def do_unprepare(self) -> bool: ...
    def do_write(self, data: Sequence[int]) -> int: ...
    

class AudioSinkClass(GObject.GPointer):
    parent_class: AudioBaseSinkClass = ...
    open: Callable[[AudioSink], bool] = ...
    prepare: Callable[[AudioSink, AudioRingBufferSpec], bool] = ...
    unprepare: Callable[[AudioSink], bool] = ...
    close: Callable[[AudioSink], bool] = ...
    write: Callable[[AudioSink, Sequence[int]], int] = ...
    delay: Callable[[AudioSink], int] = ...
    reset: Callable[[AudioSink], None] = ...
    pause: Callable[[AudioSink], None] = ...
    resume: Callable[[AudioSink], None] = ...
    stop: Callable[[AudioSink], None] = ...
    extension: AudioSinkClassExtension = ...

class AudioSinkClassExtension(GObject.GPointer):
    clear_all: Callable[[AudioSink], None] = ...

class AudioSrc(AudioBaseSrc):
    class Props:
        actual_buffer_time: int
        actual_latency_time: int
        buffer_time: int
        latency_time: int
        provide_clock: bool
        slave_method: AudioBaseSrcSlaveMethod
        blocksize: int
        do_timestamp: bool
        num_buffers: int
        typefind: bool
        name: Optional[str]
        parent: Optional[Gst.Object]
    props: Props = ...
    element: AudioBaseSrc = ...
    thread: GLib.Thread = ...
    _gst_reserved: list[None] = ...
    def __init__(self, buffer_time: int = ...,
                 latency_time: int = ...,
                 provide_clock: bool = ...,
                 slave_method: AudioBaseSrcSlaveMethod = ...,
                 blocksize: int = ...,
                 do_timestamp: bool = ...,
                 num_buffers: int = ...,
                 typefind: bool = ...,
                 name: Optional[str] = ...,
                 parent: Gst.Object = ...): ...
    def do_close(self) -> bool: ...
    def do_delay(self) -> int: ...
    def do_open(self) -> bool: ...
    def do_prepare(self, spec: AudioRingBufferSpec) -> bool: ...
    def do_read(self, data: Sequence[int]) -> Tuple[int, int]: ...
    def do_reset(self) -> None: ...
    def do_unprepare(self) -> bool: ...
    

class AudioSrcClass(GObject.GPointer):
    parent_class: AudioBaseSrcClass = ...
    open: Callable[[AudioSrc], bool] = ...
    prepare: Callable[[AudioSrc, AudioRingBufferSpec], bool] = ...
    unprepare: Callable[[AudioSrc], bool] = ...
    close: Callable[[AudioSrc], bool] = ...
    read: Callable[[AudioSrc, Sequence[int]], Tuple[int, int]] = ...
    delay: Callable[[AudioSrc], int] = ...
    reset: Callable[[AudioSrc], None] = ...
    _gst_reserved: list[None] = ...

class AudioStreamAlign(GObject.GBoxed):
    def copy(self) -> AudioStreamAlign: ...
    def free(self) -> None: ...
    def get_alignment_threshold(self) -> int: ...
    def get_discont_wait(self) -> int: ...
    def get_rate(self) -> int: ...
    def get_samples_since_discont(self) -> int: ...
    def get_timestamp_at_discont(self) -> int: ...
    def mark_discont(self) -> None: ...
    @classmethod
    def new(cls, rate: int, alignment_threshold: int, discont_wait: int) -> AudioStreamAlign: ...
    def process(self, discont: bool, timestamp: int, n_samples: int) -> Tuple[bool, int, int, int]: ...
    def set_alignment_threshold(self, alignment_threshold: int) -> None: ...
    def set_discont_wait(self, discont_wait: int) -> None: ...
    def set_rate(self, rate: int) -> None: ...
    

class StreamVolume(GObject.GInterface):
    @staticmethod
    def convert_volume(from_: StreamVolumeFormat, to: StreamVolumeFormat, val: float) -> float: ...
    def get_mute(self) -> bool: ...
    def get_volume(self, format: StreamVolumeFormat) -> float: ...
    def set_mute(self, mute: bool) -> None: ...
    def set_volume(self, format: StreamVolumeFormat, val: float) -> None: ...
    

class StreamVolumeInterface(GObject.GPointer):
    iface: GObject.TypeInterface = ...

class AudioChannelMixerFlags(GObject.GFlags):
    NONE = 0
    NON_INTERLEAVED_IN = 1
    NON_INTERLEAVED_OUT = 2
    UNPOSITIONED_IN = 4
    UNPOSITIONED_OUT = 8

class AudioConverterFlags(GObject.GFlags):
    IN_WRITABLE = 1
    NONE = 0
    VARIABLE_RATE = 2

class AudioFlags(GObject.GFlags):
    NONE = 0
    UNPOSITIONED = 1

class AudioFormatFlags(GObject.GFlags):
    COMPLEX = 16
    FLOAT = 2
    INTEGER = 1
    SIGNED = 4
    UNPACK = 32

class AudioPackFlags(GObject.GFlags):
    NONE = 0
    TRUNCATE_RANGE = 1

class AudioQuantizeFlags(GObject.GFlags):
    NONE = 0
    NON_INTERLEAVED = 1

class AudioResamplerFlags(GObject.GFlags):
    NONE = 0
    NON_INTERLEAVED_IN = 1
    NON_INTERLEAVED_OUT = 2
    VARIABLE_RATE = 4

class AudioBaseSinkDiscontReason(GObject.GEnum):
    ALIGNMENT = 4
    DEVICE_FAILURE = 5
    FLUSH = 2
    NEW_CAPS = 1
    NO_DISCONT = 0
    SYNC_LATENCY = 3

class AudioBaseSinkSlaveMethod(GObject.GEnum):
    CUSTOM = 3
    NONE = 2
    RESAMPLE = 0
    SKEW = 1

class AudioBaseSrcSlaveMethod(GObject.GEnum):
    NONE = 3
    RESAMPLE = 0
    RE_TIMESTAMP = 1
    SKEW = 2

class AudioCdSrcMode(GObject.GEnum):
    CONTINUOUS = 1
    NORMAL = 0

class AudioChannelPosition(GObject.GEnum):
    BOTTOM_FRONT_CENTER = 21
    BOTTOM_FRONT_LEFT = 22
    BOTTOM_FRONT_RIGHT = 23
    FRONT_CENTER = 2
    FRONT_LEFT = 0
    FRONT_LEFT_OF_CENTER = 6
    FRONT_RIGHT = 1
    FRONT_RIGHT_OF_CENTER = 7
    INVALID = -1
    LFE1 = 3
    LFE2 = 9
    MONO = -2
    NONE = -3
    REAR_CENTER = 8
    REAR_LEFT = 4
    REAR_RIGHT = 5
    SIDE_LEFT = 10
    SIDE_RIGHT = 11
    SURROUND_LEFT = 26
    SURROUND_RIGHT = 27
    TOP_CENTER = 15
    TOP_FRONT_CENTER = 14
    TOP_FRONT_LEFT = 12
    TOP_FRONT_RIGHT = 13
    TOP_REAR_CENTER = 20
    TOP_REAR_LEFT = 16
    TOP_REAR_RIGHT = 17
    TOP_SIDE_LEFT = 18
    TOP_SIDE_RIGHT = 19
    WIDE_LEFT = 24
    WIDE_RIGHT = 25

class AudioDitherMethod(GObject.GEnum):
    NONE = 0
    RPDF = 1
    TPDF = 2
    TPDF_HF = 3

class AudioFormat(GObject.GEnum):
    ENCODED = 1
    F32 = 28
    F32BE = 29
    F32LE = 28
    F64 = 30
    F64BE = 31
    F64LE = 30
    S16 = 4
    S16BE = 5
    S16LE = 4
    S18 = 24
    S18BE = 25
    S18LE = 24
    S20 = 20
    S20BE = 21
    S20LE = 20
    S24 = 16
    S24BE = 17
    S24LE = 16
    S24_32 = 8
    S24_32BE = 9
    S24_32LE = 8
    S32 = 12
    S32BE = 13
    S32LE = 12
    S8 = 2
    U16 = 6
    U16BE = 7
    U16LE = 6
    U18 = 26
    U18BE = 27
    U18LE = 26
    U20 = 22
    U20BE = 23
    U20LE = 22
    U24 = 18
    U24BE = 19
    U24LE = 18
    U24_32 = 10
    U24_32BE = 11
    U24_32LE = 10
    U32 = 14
    U32BE = 15
    U32LE = 14
    U8 = 3
    UNKNOWN = 0
    @staticmethod
    def build_integer(sign: bool, endianness: int, width: int, depth: int) -> AudioFormat: ...
    @staticmethod
    def fill_silence(info: AudioFormatInfo, dest: Sequence[int]) -> None: ...
    @staticmethod
    def from_string(format: str) -> AudioFormat: ...
    @staticmethod
    def get_info(format: AudioFormat) -> AudioFormatInfo: ...
    @staticmethod
    def to_string(format: AudioFormat) -> str: ...

class AudioLayout(GObject.GEnum):
    INTERLEAVED = 0
    NON_INTERLEAVED = 1

class AudioNoiseShapingMethod(GObject.GEnum):
    ERROR_FEEDBACK = 1
    HIGH = 4
    MEDIUM = 3
    NONE = 0
    SIMPLE = 2

class AudioResamplerFilterInterpolation(GObject.GEnum):
    CUBIC = 2
    LINEAR = 1
    NONE = 0

class AudioResamplerFilterMode(GObject.GEnum):
    AUTO = 2
    FULL = 1
    INTERPOLATED = 0

class AudioResamplerMethod(GObject.GEnum):
    BLACKMAN_NUTTALL = 3
    CUBIC = 2
    KAISER = 4
    LINEAR = 1
    NEAREST = 0

class AudioRingBufferFormatType(GObject.GEnum):
    AC3 = 7
    A_LAW = 2
    DTS = 9
    EAC3 = 8
    FLAC = 14
    GSM = 5
    IEC958 = 6
    IMA_ADPCM = 3
    MPEG = 4
    MPEG2_AAC = 10
    MPEG2_AAC_RAW = 12
    MPEG4_AAC = 11
    MPEG4_AAC_RAW = 13
    MU_LAW = 1
    RAW = 0

class AudioRingBufferState(GObject.GEnum):
    ERROR = 3
    PAUSED = 1
    STARTED = 2
    STOPPED = 0

class StreamVolumeFormat(GObject.GEnum):
    CUBIC = 1
    DB = 2
    LINEAR = 0

